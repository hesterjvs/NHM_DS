{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c758f4f4-c40c-4171-8af9-58a239711919",
   "metadata": {},
   "source": [
    "# Cluster images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b39041-8858-4b28-8a1e-ff3adae4e18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import silhouette_score, davies_bouldin_score\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2  # Ensure OpenCV is installed\n",
    "\n",
    "# Load the CSV file\n",
    "df = pd.read_csv('NML_Descriptions_to_score.csv', encoding='utf-8')\n",
    "\n",
    "# Assuming your CSV has a column 'Extracted Image Path' that contains image paths\n",
    "image_paths = df['Extracted Image Path'].dropna().tolist()  # Drop any NaN values\n",
    "\n",
    "# Function to extract features from an image using a pre-trained model\n",
    "def extract_image_features(image_path):\n",
    "    if not os.path.exists(image_path):  # Check if the image file exists\n",
    "        return None  # Return None if image is not found\n",
    "    try:\n",
    "        img = cv2.imread(image_path)  # OpenCV for image loading\n",
    "        img = cv2.resize(img, (224, 224))  # Resize image to match model input\n",
    "        img_array = np.array(img, dtype=np.float32)  # Convert image to array\n",
    "        img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n",
    "        img_array = tf.keras.applications.resnet50.preprocess_input(img_array)\n",
    "        features = model.predict(img_array, verbose=0)  # Suppress verbose output\n",
    "        return features.flatten()  # Flatten features for clustering\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing image {image_path}: {e}\")\n",
    "        return None  # Return None if there is an issue with the image\n",
    "\n",
    "# Load the pre-trained model for feature extraction\n",
    "model = tf.keras.applications.ResNet50(weights='imagenet', include_top=False, pooling='avg')\n",
    "\n",
    "# Extract features from all images\n",
    "features = []\n",
    "valid_image_paths = []\n",
    "for path in image_paths:\n",
    "    feature = extract_image_features(path)\n",
    "    if feature is not None:  # Only append valid features\n",
    "        features.append(feature)\n",
    "        valid_image_paths.append(path)  # Keep track of valid image paths\n",
    "\n",
    "# Check if features were extracted successfully\n",
    "if len(features) == 0:\n",
    "    print(\"No valid features extracted. Check your image paths.\")\n",
    "else:\n",
    "    # Apply PCA to reduce dimensionality\n",
    "    pca = PCA(n_components=50)  # Reduce to 50 components\n",
    "    reduced_features = pca.fit_transform(features)\n",
    "\n",
    "    # Elbow Method (for determining optimal k)\n",
    "    distortions = []\n",
    "    K_range = range(1, 11)  # Try different values of k (1 to 10)\n",
    "    for k in K_range:\n",
    "        kmeans = KMeans(n_clusters=k, verbose=0)  # Suppress verbose output\n",
    "        kmeans.fit(reduced_features)\n",
    "        distortions.append(kmeans.inertia_)\n",
    "\n",
    "    # Plot Elbow Method\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(K_range, distortions, marker='o')\n",
    "    plt.title('Elbow Method for Optimal k (Best K: Elbow point)')\n",
    "    plt.xlabel('Number of clusters (k)')\n",
    "    plt.ylabel('Distortion (Inertia)')\n",
    "    plt.show()\n",
    "\n",
    "    # Silhouette Score (for evaluating the clustering quality)\n",
    "    silhouette_scores = []\n",
    "    for k in K_range[1:]:  # Start from 2 clusters (since silhouette score requires at least 2 clusters)\n",
    "        kmeans = KMeans(n_clusters=k, verbose=0)  # Suppress verbose output\n",
    "        kmeans.fit(reduced_features)\n",
    "        score = silhouette_score(reduced_features, kmeans.labels_)\n",
    "        silhouette_scores.append(score)\n",
    "\n",
    "    # Plot Silhouette Scores\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(K_range[1:], silhouette_scores, marker='o', color='g')\n",
    "    plt.title('Silhouette Scores for Different k. (A higher score (closer to 1) indicates better-defined clusters)')\n",
    "    plt.xlabel('Number of clusters (k)')\n",
    "    plt.ylabel('Silhouette Score')\n",
    "    plt.show()\n",
    "\n",
    "    # Davies-Bouldin Index (for evaluating how well-separated the clusters are)\n",
    "    davies_bouldin_scores = []\n",
    "    for k in K_range[1:]:\n",
    "        kmeans = KMeans(n_clusters=k, verbose=0)  # Suppress verbose output\n",
    "        kmeans.fit(reduced_features)\n",
    "        score = davies_bouldin_score(reduced_features, kmeans.labels_)\n",
    "        davies_bouldin_scores.append(score)\n",
    "\n",
    "    # Plot Davies-Bouldin Index Scores\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(K_range[1:], davies_bouldin_scores, marker='o', color='r')\n",
    "    plt.title('Davies-Bouldin Index for Different k. (A lower score indicates well-separated clusters)')\n",
    "    plt.xlabel('Number of clusters (k)')\n",
    "    plt.ylabel('Davies-Bouldin Index')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f5696f-786e-4705-aa78-cf45602da7dc",
   "metadata": {},
   "source": [
    "# Take a decition for optimal number of clusters (k) based on the Elbow method, Davies-Bouldin Index, and Silhouette Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e7b20d31-30ff-4b00-b437-d57bc50ee384",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustering results saved to 'clustered_images_with_metrics.csv'.\n"
     ]
    }
   ],
   "source": [
    "# Perform final KMeans clustering with optimal k (based on your chosen evaluation metric)\n",
    "optimal_k = 4  # For example, if k=3 seems optimal from your evaluation\n",
    "kmeans = KMeans(n_clusters=optimal_k, verbose=0)  # Suppress verbose output\n",
    "kmeans.fit(reduced_features)\n",
    "\n",
    "# Map images to clusters\n",
    "image_cluster_map = {valid_image_paths[i]: kmeans.labels_[i] for i in range(len(valid_image_paths))}\n",
    "\n",
    "# Optionally, save the mapping to a new CSV file\n",
    "df['Cluster'] = df['Extracted Image Path'].map(image_cluster_map)\n",
    "df.to_csv('clustered_images_with_metrics.csv', index=False)\n",
    "print(\"Clustering results saved to 'clustered_images_with_metrics.csv'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ede1ac-a035-450d-9ce5-34855e2b47f0",
   "metadata": {},
   "source": [
    "# Display a subset of images in each cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c65494-938b-4f94-b558-40564edbe4b9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from PIL import Image, ImageOps\n",
    "from IPython.display import display\n",
    "import IPython.display as ipd\n",
    "\n",
    "# Load the CSV file\n",
    "csv_path = \"clustered_images_with_metrics.csv\"\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# Ensure correct column names\n",
    "image_column = \"Extracted Image Path\"\n",
    "cluster_column = \"Cluster\"\n",
    "\n",
    "# Filter out rows where the cluster label is NaN\n",
    "df = df[df[cluster_column].notna()]\n",
    "\n",
    "# Get unique non-empty clusters\n",
    "non_empty_clusters = [cluster for cluster in df[cluster_column].unique() if df[df[cluster_column] == cluster][image_column].notna().sum() > 0]\n",
    "\n",
    "# Define a dictionary of background colors for each cluster\n",
    "cluster_colors = {\n",
    "    0: (220, 200, 200),  # Light mint green for Cluster 1\n",
    "    1: (255, 240, 200),  # Light yellow for Cluster 2\n",
    "    2: (200, 220, 240),  # Light blue for Cluster 3\n",
    "    3: (220, 240, 240),  # Soft turquoise for Cluster 4\n",
    "    4: (240, 240, 200),  # Light cream for Cluster 5\n",
    "    5: (240, 240, 240),  # Light lavender for Cluster 6\n",
    "    6: (200, 240, 220),  # Light aqua for Cluster 7\n",
    "    7: (240, 230, 200),  # Light beige for Cluster 8\n",
    "    8: (220, 220, 240),  # Light periwinkle for Cluster 9\n",
    "    # Add more clusters and colors as needed\n",
    "}\n",
    "\n",
    "# Function to pad images while keeping aspect ratio\n",
    "def pad_image(img, size=256, bg_color=(220, 200, 200)):  # Default background color\n",
    "    \"\"\"Resizes an image to fit within a square while maintaining aspect ratio, padding with a background color.\"\"\"\n",
    "    img.thumbnail((size, size), Image.Resampling.LANCZOS)  # Resize while maintaining aspect ratio\n",
    "    new_img = Image.new(\"RGB\", (size, size), bg_color)  # Create a square canvas\n",
    "    x_offset = (size - img.size[0]) // 2  # Center the image\n",
    "    y_offset = (size - img.size[1]) // 2\n",
    "    new_img.paste(img, (x_offset, y_offset))\n",
    "    return new_img\n",
    "\n",
    "# Function to save and display images for a given cluster\n",
    "def save_and_display_images_for_cluster(cluster_df, cluster_label, output_dir=\"output_images\"):\n",
    "    images = cluster_df[image_column].dropna().tolist()[:9]  # Get first 9 images\n",
    "\n",
    "    # Create the output directory if it doesn't exist\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Set the background color for the cluster\n",
    "    bg_color = cluster_colors.get(int(cluster_label), (220, 200, 200))  # Default to mint green if not defined\n",
    "\n",
    "    fig, axes = plt.subplots(3, 3, figsize=(9, 9))\n",
    "    fig.suptitle(f\"Cluster {int(cluster_label)}\", fontsize=16)  # Force integer display\n",
    "\n",
    "    for ax, img_path in zip(axes.flatten(), images):\n",
    "        if os.path.exists(img_path):\n",
    "            img = Image.open(img_path)\n",
    "            img = pad_image(img, bg_color=bg_color)  # Use the cluster's background color\n",
    "            ax.imshow(img)\n",
    "            ax.set_title(os.path.basename(img_path), fontsize=8)\n",
    "        else:\n",
    "            ax.set_title(\"Not Found\", fontsize=8)\n",
    "        ax.axis(\"off\")\n",
    "\n",
    "    # Hide any empty subplots if <9 images\n",
    "    for i in range(len(images), 9):\n",
    "        axes.flatten()[i].axis(\"off\")\n",
    "\n",
    "    # Save the figure as a JPG file\n",
    "    cluster_filename = os.path.join(output_dir, f\"cluster_{int(cluster_label)}.jpg\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(cluster_filename, format=\"jpg\", dpi=300)\n",
    "    plt.show()  # Display the figure in the notebook\n",
    "\n",
    "# Loop through the original clusters (after removing NaN entries)\n",
    "original_clusters = sorted(df[cluster_column].unique())\n",
    "\n",
    "for original_cluster in original_clusters:  # Use original cluster labels\n",
    "    cluster_df = df[df[cluster_column] == original_cluster]\n",
    "    save_and_display_images_for_cluster(cluster_df, original_cluster)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
